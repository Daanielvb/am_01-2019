# -*- coding: utf-8 -*-
"""Projeto1AM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KIWksJfX23uneVeRbAWEgVa1biZRXHvP
"""

import importlib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

from sklearn.metrics.cluster import adjusted_rand_score
from time import time


def fuzzy_partition(count):
    start = time()
    # algorithm parameters
    K = 10  # number of partitions
    m = 1.6  # fuzzification parameter
    T = 150
    e = 10e-10

    p = 3  # number of views
    n = 2000

    # importing datasets
    fac_dataset = pd.read_csv('mfeat_fac.csv', header=None)
    fou_dataset = pd.read_csv('mfeat_fou.csv', header=None)
    kar_dataset = pd.read_csv('mfeat_kar.csv', header=None)

    # convert data frames to array
    fac_view = fac_dataset.iloc[:, :].values
    fou_view = fou_dataset.iloc[:, :].values
    kar_view = kar_dataset.iloc[:, :].values

    # Normalize matrixes (feature scaling)
    fac_norm = feature_scaling_matrix(fac_view)
    fou_norm = feature_scaling_matrix(fou_view)
    kar_norm = feature_scaling_matrix(kar_view)

    # compute dissimilarity matrixes
    fac_dis = dissimilarity_matrix(matrix=fac_norm, size=n)
    fou_dis = dissimilarity_matrix(matrix=fou_norm, size=n)
    kar_dis = dissimilarity_matrix(matrix=kar_norm, size=n)

    dis_matrix = [fac_dis, fou_dis, kar_dis]

    # randomize prototypes matrix
    G = np.random.choice(n, size=(K, p), replace=False)

    # weigth vector
    l = [1.,1.,1.]

    # create membership matrix
    U = np.zeros((n, K), dtype=float)

    # compute membership matrix
    q=3
    for u in range(0, n):
        for k in range(0, K):
            U[u][k] = object_membership(u, k, K, m, p, q, l, dis_matrix, G)

    # compute objective function
    J = objective_function(n, p, q, m, K, U, l, dis_matrix, G)
    last_J = J + 300

    t = 0
    while ((abs(J - last_J) >= e) and (t < T)):
        last_J = J
        """Step 1"""
        # compute best prototypes
        G = compute_prototypes_sorting(n, p, q, m, K, l, dis_matrix, G, U)

        """Step 2"""
        # compute best relevance weigth vector
        l = compute_weigths(n, p, q, m, K, l, dis_matrix, U, G)

        """Step 3"""
        # definition of best Fuzzy Partition
        for u in range(0, n):
            for k in range(0, K):
                U[u][k] = object_membership(u, k, K, m, p, q, l, dis_matrix, G)

        # compute objective function to check stop criterion
        J = objective_function(n, p, q, m, K, U, l, dis_matrix, G)

        t += 1
        # printing some iteration outputs
        print(" objective function on interaction %d is %f " % (t, J))

    # calculate Hard Partition
    y = hard_partition(n, K, U)

    # compare hard partition with true classes
    
    rand_score = adjusted_rand_score(Y, y)

    filename = "outFile.txt"

    file = open(filename, "a")
    file.write("Data of interaction " + str(count))
    file.write("J = " + str(J) + "\n")
    file.write("Rand = " + str(rand_score) + "\n")
    file.close()

    write_array_to_file(filename, G, "Prototipos")
    write_array_to_file(filename, l, "Pesos")

    file_patition = "partitions/partition" + str(count) + ".txt"
    np.savetxt(file_patition, y, fmt='%d', delimiter=",",
               header="Para carregar em um array, usar numpy.loadtxt()",
               comments="#")

    elapsed = time() - start

    return [rand_score, J, G, l, U, y, elapsed]

def euclidean_distance(a, b):
    return np.linalg.norm(a - b)


def feature_scaling_matrix(matrix):
    min_value = np.min(matrix)
    max_value = np.max(matrix)
    matrix = (matrix - min_value) / (max_value - min_value)
    return matrix


def normalize_residuals_matrix(matrix):
    mean_value = np.mean(matrix)
    std_value = np.std(matrix)
    matrix = (matrix - mean_value) / std_value
    return matrix


def dissimilarity_matrix(matrix, size):
    dis_matrix = np.zeros((size, size), dtype=float)
    for i in range(0, size):
        for j in range(0, size):
            dis_matrix[i, j] = euclidean_distance(a=matrix[i, :], b=matrix[j, :])
    return dis_matrix


def object_membership(obj, proto, K, m, n_views, n_proto, l, m_dis, G):
    membership = 0
    # atÃ© aqui ta OK
    distance = dist_object_proto(obj, proto, n_views, n_proto, l, m_dis, G)
    for k in range(0, K):
        membership += np.power((distance / dist_object_proto(obj, k, n_views, n_proto, l, m_dis, G)), (1 / (m - 1)))

    membership = np.power(membership, -1)
    return membership


def dist_object_proto(obj, proto, n_views, n_proto, l, m_dis, G):
    acc = 0
    # sum distances for j views
    for j in range(0, n_views):
        d_acc = 0
        # sum of distance to i objs in view j
        for i in range(0, n_proto):
            obj_i_proto = G[proto][i]
            d_acc += m_dis[j][obj][obj_i_proto]
        acc += l[j] * d_acc
    return acc


def objective_function(n, p, q, m, K, U, l, m_dis, G):
    objective = 0
    for k in range(0, K):
        for i in range(0, n):
            objective += np.power(U[i][k], m) * dist_object_proto(i, k, p, q, l, m_dis, G)
    return objective


def compute_prototypes(n, p, q, m, K, l, m_dis, G, U):
    dist_vector = np.zeros(n, dtype=float)
    for k in range(0, K):
        for h in range(0, n):
            acc = 0
            for i in range(0, n):
                d_acc = 0
                for j in range(0, p):
                    d_acc += l[j] * m_dis[j][i][h]
                acc += np.power(U[i][k], m) * d_acc
            dist_vector[h] = acc
        max_value = np.max(dist_vector)
        for g in range(0, q):
            G[k][g] = np.argmin(dist_vector)
            dist_vector[G[k][g]] = max_value
    return G


def compute_prototypes_sorting(n, p, q, m, K, l, m_dis, G, U):
    dist_vector = np.zeros(n, dtype=float)
    for k in range(0, K):
        for h in range(0, n):
            acc = 0
            for i in range(0, n):
                d_acc = 0
                for j in range(0, p):
                    d_acc += l[j] * m_dis[j][i][h]
                acc += np.power(U[i][k], m) * d_acc
            dist_vector[h] = acc
        sorted_arguments = np.argsort(dist_vector)
        for g in range(0, q):
            G[k][g] = sorted_arguments[g]
    return G


def compute_weigths(n, p, q, m, K, l, m_dis, U, G):
    sum_vector = np.zeros(p, dtype=float)
    for j in range(0, p):
        sum_acc = 0
        for k in range(0, K):
            acc = 0
            for i in range(0, n):
                d_acc = 0
                for g in range(0, q):
                    g_index = G[k][g]
                    d_acc += m_dis[j][i][g_index]
                acc += np.power(U[i][k], m) * d_acc
            sum_acc += acc
        sum_vector[j] = sum_acc
    num_value = np.power(np.prod(sum_vector), (1 / p))

    for j in range(0, p):
        l[j] = num_value / sum_vector[j]
    return l


def hard_partition(n, K, U):
    y = np.zeros(n, dtype=int)
    for i in range(0, n):
        y[i] = np.argmax(U[i])
    return y


def write_array_to_file(filename, arr, variable_name):
    file = open(filename, "a")
    file.write(variable_name + "\n")
    for line in arr:
        try:
            file.write(str(line) + "\n")
        except Exception:
            file.write(np.array_str(line) + "\n")
    file.write("\n")
    file.close()

for n in range(0, 1):
    [rand_score[n], J[n], G[n], l[n], U[n], y[n], elapsed[n]] = fuzzy_partition(n)

np.average(rand_score)
np.argmax(rand_score)
max(rand_score)
rand_score[83]
J[83]

np.average(J)
np.argmin(J)
min(J)
J[62]

np.mean(elapsed)

plt.plot(feature_scaling_matrix(rand_score[70:90]), label="Rand Corrigido")
plt.plot(feature_scaling_matrix(J[70:90]), label="FunÃ§Ã£o Objetivo")
plt.legend()
plt.show()